{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mano-2410/pulmonary-Nodule-detection-and-Classification-using-deep-learning-algorithm/blob/Master/PulmonaryLungNoduleDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df86b6c7-99c5-47e3-84e0-583820373daf",
      "metadata": {
        "id": "df86b6c7-99c5-47e3-84e0-583820373daf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage import measure\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94946a62-f3e3-460d-8c2d-959f4d5e9611",
      "metadata": {
        "id": "94946a62-f3e3-460d-8c2d-959f4d5e9611"
      },
      "outputs": [],
      "source": [
        "dataRoot = \"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/The IQ-OTHNCCD lung cancer dataset/The IQ-OTHNCCD lung cancer dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6cTYzs4DP3t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6cTYzs4DP3t",
        "outputId": "85ff62b5-f150-4a56-f605-3424967814bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705795fd-9342-452b-89ec-62dbda9cc439",
      "metadata": {
        "id": "705795fd-9342-452b-89ec-62dbda9cc439"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197f2c2a-f4ff-4aaa-9254-d553fd17f6f2",
      "metadata": {
        "id": "197f2c2a-f4ff-4aaa-9254-d553fd17f6f2"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/models/v1/UNet_model.h5\", custom_objects={'dice_coef':dice_coef, 'dice_coef_loss':dice_coef_loss})\n",
        "model2 = tf.keras.models.load_model(\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/models/v1/FPR_classifier_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P37IS3lxjgmu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P37IS3lxjgmu",
        "outputId": "8c533acc-3e43-490b-882f-751b4c3a0e4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nbformat/__init__.py:132: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
            "  validate(nb)\n"
          ]
        }
      ],
      "source": [
        "import nbformat as nbf\n",
        "def merge_notebooks(filenames):\n",
        "    merged = nbf.v4.new_notebook()\n",
        "    for fname in filenames:\n",
        "        with open(fname) as f:\n",
        "            nb = nbf.read(f, as_version=4)\n",
        "            merged.cells.extend(nb.cells)\n",
        "    return merged\n",
        "\n",
        "notebooks_to_merge = [\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/01_Lungs_Segmentation.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/02_Nodule_Mask_Extraction.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/03_v2_Lungs ROI & Nodule Mask extraction from LUNA16 dataset.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/04_Dataset_Preparation.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/05_UNet_Training.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/06_Ground_Truth_vs_Prediction_visualization.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/07_FPR_Candidate_ROI_extraction.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/08_FPR_Dataset_Creation.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/09_FPR_CNN_Training.ipynb\",\n",
        "\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/10_LC_FPR_CNN_Evaluation.ipynb\",\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/notebooks/v1/FPR_data_lookup.ipynb\"]\n",
        "\n",
        "merged_notebook = merge_notebooks(notebooks_to_merge);\n",
        "with open(\"merged_notebook.ipynb\", \"w\") as f:\n",
        "    nbf.write(merged_notebook, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bxgVBr1pQ1vQ",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxgVBr1pQ1vQ",
        "outputId": "021574e0-de41-46e4-d6a5-35e3037eb1ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/usr/local/etc/jupyter/jupyter_notebook_config.d/ipyparallel.json\n",
            "    \t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json\n",
            "    \t/usr/local/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/usr/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/root/.local/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/root/.jupyter/jupyter_notebook_config.json\n",
            "\n",
            "  _   _          _      _\n",
            " | | | |_ __  __| |__ _| |_ ___\n",
            " | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "  \\___/| .__/\\__,_\\__,_|\\__\\___|\n",
            "       |_|\n",
            "                       \n",
            "Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions.\n",
            "\n",
            "https://jupyter-notebook.readthedocs.io/en/latest/migrate_to_notebook7.html\n",
            "\n",
            "Please note that updating to Notebook 7 might break some of your extensions.\n",
            "\n",
            "|INFO|google.colab serverextension initialized.\n",
            "|INFO|Loading IPython parallel extension\n",
            "|INFO|Serving notebooks from local directory: /content\n",
            "|INFO|Jupyter Notebook 6.5.5 is running at:\n",
            "|INFO|http://localhost:8888/?token=db44d376c4c5af766a2315d355b8fdb3a6d6107b8d3bad7a\n",
            "|INFO| or http://127.0.0.1:8888/?token=db44d376c4c5af766a2315d355b8fdb3a6d6107b8d3bad7a\n",
            "|INFO|Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
            "|WARNING|No web browser found: could not locate runnable browser.\n",
            "|CRITICAL|\n",
            "    \n",
            "    To access the notebook, open this file in a browser:\n",
            "        file:///root/.local/share/jupyter/runtime/nbserver-5544-open.html\n",
            "    Or copy and paste one of these URLs:\n",
            "        http://localhost:8888/?token=db44d376c4c5af766a2315d355b8fdb3a6d6107b8d3bad7a\n",
            "     or http://127.0.0.1:8888/?token=db44d376c4c5af766a2315d355b8fdb3a6d6107b8d3bad7a\n"
          ]
        }
      ],
      "source": [
        "!jupyter notebook merged_notebook.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b039207-7317-46f9-b81d-2c69fbe5ba93",
      "metadata": {
        "id": "6b039207-7317-46f9-b81d-2c69fbe5ba93"
      },
      "outputs": [],
      "source": [
        "mfiles = os.listdir(dataRoot+\"/Malignant cases/\")\n",
        "random.shuffle(mfiles)\n",
        "mfiles = mfiles[:30]\n",
        "bfiles = os.listdir(dataRoot+\"/Bengin cases/\")\n",
        "random.shuffle(bfiles)\n",
        "bfiles = bfiles[:30]\n",
        "nfiles = os.listdir(dataRoot+\"/Normal cases/\")\n",
        "random.shuffle(nfiles)\n",
        "nfiles = nfiles[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c1771a-dde8-42b9-9434-a09e7305da24",
      "metadata": {
        "id": "41c1771a-dde8-42b9-9434-a09e7305da24"
      },
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "    if img.max()>255 or img.max()<1.5 or img.min()<0:\n",
        "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    if len(img.shape) > 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    img = cv2.resize(img, (512,512))\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    img_improved = clahe.apply(img.astype(np.uint8))\n",
        "    # img_improved = img.copy()\n",
        "\n",
        "    contours, hirearchy = cv2.findContours(external_contours,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    external_contours = np.zeros(external_contours.shape)\n",
        "    centeral_area = img[100:400, 100:400]\n",
        "    kmeans = KMeans(n_clusters=2).fit(np.reshape(centeral_area, [np.prod(centeral_area.shape), 1]))\n",
        "    centroids = sorted(kmeans.cluster_centers_.flatten())\n",
        "    threshold = np.mean(centroids)\n",
        "    ret, lung_roi = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY_INV)\n",
        "    lung_roi = cv2.erode(lung_roi, kernel=np.ones([4,4]))\n",
        "    lung_roi = cv2.dilate(lung_roi, kernel=np.ones([13,13]))\n",
        "    lung_roi = cv2.erode(lung_roi, kernel=np.ones([8,8]))\n",
        "\n",
        "    labels = measure.label(lung_roi)\n",
        "    regions = measure.regionprops(labels)\n",
        "    good_labels = []\n",
        "    for prop in regions:\n",
        "        B = prop.bbox\n",
        "        if B[2]-B[0] < 500 and B[3]-B[1] < 490 and B[0] > 17 and B[2] < 495:\n",
        "            good_labels.append(prop.label)\n",
        "    lung_roi_mask = np.zeros_like(labels)\n",
        "    for N in good_labels:\n",
        "        lung_roi_mask = lung_roi_mask + np.where(labels == N, 1, 0)\n",
        "\n",
        "    contours, hirearchy = cv2.findContours(lung_roi_mask,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    external_contours = np.zeros(lung_roi_mask.shape)\n",
        "    for i in range(len(contours)):\n",
        "        if hirearchy[0][i][3] == -1:  #External Contours\n",
        "            area = cv2.contourArea(contours[i])\n",
        "            if area>518.0:\n",
        "                cv2.drawContours(external_contours,contours,i,(1,1,1),-1)\n",
        "    external_contours = cv2.dilate(external_contours, kernel=np.ones([4,4]))\n",
        "\n",
        "    external_contours = cv2.bitwise_not(external_contours.astype(np.uint8))\n",
        "    external_contours = cv2.erode(external_contours, kernel=np.ones((7,7)))\n",
        "    external_contours = cv2.bitwise_not(external_contours)\n",
        "    external_contours = cv2.dilate(external_contours, kernel=np.ones((12,12)))\n",
        "    external_contours = cv2.erode(external_contours, kernel=np.ones((12,12)))\n",
        "\n",
        "    contours, hirearchy = cv2.findContours(external_contours,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    external_contours2 = np.zeros(external_contours.shape)\n",
        "    for i in range(len(contours)):\n",
        "        if hirearchy[0][i][3] == -1:  #External Contours\n",
        "            area = cv2.contourArea(contours[i])\n",
        "            if area>518.0:\n",
        "                cv2.drawContours(external_contours2,contours,i,(1,1,1),-1)\n",
        "\n",
        "    img_improved = img_improved.astype(np.uint8)\n",
        "    external_contours2 = external_contours2.astype(np.uint8)\n",
        "    extracted_lungs = cv2.bitwise_and(img_improved, img_improved, mask=external_contours2)\n",
        "\n",
        "    return ((extracted_lungs-127.0)/127.0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b62b4cb-e4de-4d35-9244-0b8263bb5b1d",
      "metadata": {
        "id": "8b62b4cb-e4de-4d35-9244-0b8263bb5b1d"
      },
      "outputs": [],
      "source": [
        "def display(imgs,mask):\n",
        "    j = 1\n",
        "    for im,mk in zip(imgs,mask):\n",
        "      plt.figure(figsize=(20,300))\n",
        "      plt.subplot(50,3,j)\n",
        "      plt.imshow(np.squeeze(im), cmap=\"gray\")\n",
        "      plt.subplot(50,3,j+1)\n",
        "      plt.imshow(np.squeeze(mk), cmap=\"gray\")\n",
        "      plt.subplot(50,3,j+2)\n",
        "      plt.imshow(cv2.addWeighted(np.squeeze(im), .5, np.squeeze(mk), .5, 0), cmap=\"gray\")\n",
        "      j += 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0999a94-e8b6-4e0e-a72d-324d0b6dd717",
      "metadata": {
        "id": "a0999a94-e8b6-4e0e-a72d-324d0b6dd717"
      },
      "outputs": [],
      "source": [
        "def display2(imgs, titles=None, cmap=\"bone\"):\n",
        "    n = len(list(imgs))\n",
        "    r = n//3 if n%3==0 else (n//3)+1\n",
        "    plt.figure(figsize=(25,int(8*r)))\n",
        "    for i,img in enumerate(imgs):\n",
        "        plt.subplot(r,3,i+1)\n",
        "        if titles is not None:\n",
        "            plt.title(titles[i])\n",
        "        plt.imshow(img, cmap=cmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86cf21be-15a1-4872-932f-b3edc5537062",
      "metadata": {
        "id": "86cf21be-15a1-4872-932f-b3edc5537062"
      },
      "outputs": [],
      "source": [
        "def display_test(img, cmap='bone'):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(img, cmap=cmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93983487-3626-4de1-b0b8-49766593af0f",
      "metadata": {
        "id": "93983487-3626-4de1-b0b8-49766593af0f"
      },
      "outputs": [],
      "source": [
        "originals = []\n",
        "mimgs = []\n",
        "bimgs = []\n",
        "nimgs = []\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "for m in tqdm(mfiles):\n",
        "    img = cv2.imread(dataRoot+\"/Malignant cases/\"+m, 0)\n",
        "    originals.append(clahe.apply(cv2.resize(img, (512,512)).astype(np.uint8)))\n",
        "    img = preprocess(img)\n",
        "    mimgs.append(img)\n",
        "\n",
        "\n",
        "for m in tqdm(bfiles):\n",
        "    img = cv2.imread(dataRoot+\"Bengin cases/\"+m, 0)\n",
        "    img = preprocess(img)\n",
        "    bimgs.append(img)\n",
        "\n",
        "for m in tqdm(nfiles):\n",
        "    img = cv2.imread(dataRoot+\"Normal cases/\"+m, 0)\n",
        "    img = preprocess(img)\n",
        "    nimgs.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1423c79d-27e9-4966-a42a-32a00ef1a7da",
      "metadata": {
        "id": "1423c79d-27e9-4966-a42a-32a00ef1a7da"
      },
      "outputs": [],
      "source": [
        "mi = np.array(mimgs)\n",
        "pred = model.predict(np.reshape(mi,(len(mi),512,512,1)))\n",
        "pred[pred>=0.5] = 255\n",
        "pred[pred<0.5] = 0\n",
        "pred = pred.astype(np.uint8)\n",
        "pred = list(pred)\n",
        "mpred = [np.squeeze(i) for i in pred]\n",
        "\n",
        "# bi = np.array(bimgs)\n",
        "# pred = model.predict(np.reshape(bi,(len(bi),512,512,1)))\n",
        "# pred = list(pred)\n",
        "# bpred = [np.squeeze(i) for i in pred]\n",
        "\n",
        "# ni = np.array(nimgs)\n",
        "# pred = model.predict(np.reshape(ni,(len(ni),512,512,1)))\n",
        "# pred = list(pred)\n",
        "# npred = [np.squeeze(i) for i in pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25bf52b5-725b-4555-b234-45e4119c5341",
      "metadata": {
        "id": "25bf52b5-725b-4555-b234-45e4119c5341"
      },
      "outputs": [],
      "source": [
        "display(originals[10:15],mpred[10:15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "890d667c-53f5-4844-b135-2b2998433cec",
      "metadata": {
        "id": "890d667c-53f5-4844-b135-2b2998433cec"
      },
      "outputs": [],
      "source": [
        "bboxes = []\n",
        "for mask in mpred:\n",
        "    mask = cv2.dilate(mask, kernel=np.ones((5,5)))\n",
        "    labels = measure.label(mask)\n",
        "    regions = measure.regionprops(labels)\n",
        "    bb = []\n",
        "    for prop in regions:\n",
        "        B = prop.bbox\n",
        "        bb.append((( max(0, B[1]-10), max(0, B[0]-10) ),( min(B[3]+10, 512), min(B[2]+10, 512) )))    # ((x1,y1),(x2,y2))\n",
        "    bboxes.append(bb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85442f0d-42b3-46b7-840c-169fd52210fa",
      "metadata": {
        "id": "85442f0d-42b3-46b7-840c-169fd52210fa"
      },
      "outputs": [],
      "source": [
        "bboxes[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3db81c17-2ebf-43f3-80a1-f5f562586b4b",
      "metadata": {
        "id": "3db81c17-2ebf-43f3-80a1-f5f562586b4b"
      },
      "outputs": [],
      "source": [
        "bs = []\n",
        "o = copy.deepcopy(mimgs)\n",
        "for i,(img,boxes) in enumerate(zip(o,bboxes)):\n",
        "    for rect in boxes:\n",
        "        cv2.rectangle(img, rect[0], rect[1], (1), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432c62ce-884e-404b-adbc-8bf68f364451",
      "metadata": {
        "id": "432c62ce-884e-404b-adbc-8bf68f364451"
      },
      "outputs": [],
      "source": [
        "display2(o[10:16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cede871-a3d7-4f69-b178-625d76197d8d",
      "metadata": {
        "id": "6cede871-a3d7-4f69-b178-625d76197d8d"
      },
      "outputs": [],
      "source": [
        "o2 = copy.deepcopy(originals)\n",
        "final_boxes = []\n",
        "for i,(img,bbox) in enumerate(zip(o2, bboxes)):\n",
        "    img_boxes = []\n",
        "    for box in bbox:\n",
        "        x1 = box[0][0]\n",
        "        y1 = box[0][1]\n",
        "        x2 = box[1][0]\n",
        "        y2 = box[1][1]\n",
        "        if abs(x1-x2) <=50 or abs(y1-y2)<=50:\n",
        "            x = (x1+x2)//2\n",
        "            y = (y1+y2)//2\n",
        "            x1 = max(x-25, 0)\n",
        "            x2 = min(x+25, 512)\n",
        "            y1 = max(y-25, 0)\n",
        "            y2 = min(y+25, 512)\n",
        "            imgbox = img[y1:y2,x1:x2]\n",
        "            img_boxes.append(imgbox)\n",
        "        else:\n",
        "            imgbox = img[y1:y2,x1:x2]\n",
        "            img_boxes.append(imgbox)\n",
        "    final_boxes.append(img_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d220ae-aa1b-46c6-b9a9-09adbf8e2feb",
      "metadata": {
        "id": "e6d220ae-aa1b-46c6-b9a9-09adbf8e2feb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i,img in enumerate(final_boxes[13]):\n",
        "    plt.subplot(1,6,i+1)\n",
        "    plt.imshow(img, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec766071-b650-4426-97d5-4fe73c0954cc",
      "metadata": {
        "id": "ec766071-b650-4426-97d5-4fe73c0954cc"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for i in final_boxes:\n",
        "    each_p = []\n",
        "    for img in i:\n",
        "        if img.shape != (50,50):\n",
        "            img = np.resize(img, (50,50))\n",
        "        img = img/255.\n",
        "        img = np.reshape(img, (1,50,50,1))\n",
        "        pred = model2.predict(img)\n",
        "        pred = pred>=0.5\n",
        "        each_p.append(1)\n",
        "    predictions.append(each_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221caf4e-a060-4a3c-989d-c092002825c8",
      "metadata": {
        "id": "221caf4e-a060-4a3c-989d-c092002825c8"
      },
      "outputs": [],
      "source": [
        "final_img_bbox = []\n",
        "cancer = []\n",
        "for i,(img,bbox,preds) in enumerate(zip(mimgs, bboxes, predictions)):\n",
        "    token = False\n",
        "    for box,pred in zip(bbox,preds):\n",
        "        if pred:\n",
        "            x1 = box[0][0]\n",
        "            y1 = box[0][1]\n",
        "            x2 = box[1][0]\n",
        "            y2 = box[1][1]\n",
        "            img = cv2.rectangle(img, (x1,y1), (x2,y2), (2), 2)\n",
        "            token = True\n",
        "    final_img_bbox.append(img)\n",
        "    cancer.append(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855c8578-e257-4d7b-b3f4-21d510c14dfb",
      "metadata": {
        "id": "855c8578-e257-4d7b-b3f4-21d510c14dfb"
      },
      "outputs": [],
      "source": [
        "display2(final_img_bbox[10:16], cancer[10:16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce891899-b2d3-46f3-8cd1-980ed2151744",
      "metadata": {
        "id": "ce891899-b2d3-46f3-8cd1-980ed2151744"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fe3437d0",
      "metadata": {
        "id": "fe3437d0"
      },
      "source": [
        "# Training YOLOv5 on costume dataset Lung cancer Nodules detection\n",
        "\n",
        "In this paper , we assemble a dataset and train a custom YOLOv5 model to recognize the Nodules in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset from LIDC databased\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the lung cancer Nodules annatationed in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model perfermence on wandb W and B\n",
        "\n",
        "\n",
        "\n",
        "![](https://miro.medium.com/max/1398/1*ByicK9w-I8wdNGfdx8DJZA.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mseiTC-ZQHMO",
      "metadata": {
        "id": "mseiTC-ZQHMO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b8e7fbe",
      "metadata": {
        "id": "6b8e7fbe"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46173a9d",
      "metadata": {
        "id": "46173a9d"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eeee503",
      "metadata": {
        "id": "6eeee503"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b199fc9",
      "metadata": {
        "id": "0b199fc9"
      },
      "source": [
        "# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97bb0918",
      "metadata": {
        "id": "97bb0918"
      },
      "source": [
        "### Create Config Data File\n",
        "\n",
        "* the file config Parametes :\n",
        "    - config Data :\n",
        "        1. the data Path\n",
        "        2. Train Path\n",
        "        3. validation Path\n",
        "        4. Number Claess\n",
        "        5. name of Class\n",
        "        \n",
        "**Noatation: we will let the hyper-Parameters as defined in Yolov5s**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f02d743",
      "metadata": {
        "id": "4f02d743"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "# Define the YAML content as a Python dictionary\n",
        "data = {\n",
        "    'path': '/content/drive/MyDrive/ct_images',\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': None,  # Optional key, set to None for now\n",
        "    'nc': 1,\n",
        "    'names': ['Nodules']\n",
        "}\n",
        "\n",
        "# Specify the file path for the new YAML file\n",
        "file_path = '/content/dataconfig.yml'\n",
        "\n",
        "# Write the YAML content to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    yaml.dump(data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bffacc8",
      "metadata": {
        "id": "1bffacc8"
      },
      "outputs": [],
      "source": [
        "!cat /content/output/yolov5/dataconfig.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c162591e",
      "metadata": {
        "id": "c162591e"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install comet_ml  # 1. install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5e7738",
      "metadata": {
        "id": "cc5e7738"
      },
      "outputs": [],
      "source": [
        "!export COMET_API_KEY=YB7WECZkESGlU5uxxO43BCo5Q  # 2. paste API key\n",
        "!python /content/yolov5/train.py --img 50 --batch 16 --single-cls --epochs 3 --project cancer_Nodules_diagnosed --bbox_interval 1 --save-period 4 --data /content/dataconfig.yml --weights yolov5s.pt  # 3. train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d64e152",
      "metadata": {
        "id": "5d64e152"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54eb420e",
      "metadata": {
        "id": "54eb420e"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/yolov5/yolov5/cancer_Nodules_diagnosed/exp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94046382",
      "metadata": {
        "id": "94046382"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72a866ea",
      "metadata": {
        "id": "72a866ea"
      },
      "outputs": [],
      "source": [
        "!python /content/yolov5/val.py --weights /content/yolov5/cancer_Nodules_diagnosed/exp/weights/best.pt --single-cls --img 416 --conf 0.1 --data /content/dataconfig.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdc9b23d",
      "metadata": {
        "id": "bdc9b23d"
      },
      "outputs": [],
      "source": [
        "!python /content/yolov5/detect.py --weights /content/cancer_Nodules_diagnosed/exp/weights/best.pt --img 416 --conf 0.1 --source /content/drive/MyDrive/ct_images/images/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ba3d4c",
      "metadata": {
        "id": "20ba3d4c"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the list of image file paths\n",
        "image_paths = glob.glob('/content/yolov5/runs/detect/exp4/*.jpg')\n",
        "\n",
        "# Plot only the first six images\n",
        "num_images_to_plot = 6\n",
        "\n",
        "# Initialize the figure and axes\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "\n",
        "for i, (image_path, ax) in enumerate(zip(image_paths[:num_images_to_plot], axes.flatten())):\n",
        "    # Read and plot the image using Matplotlib\n",
        "    img = plt.imread(image_path)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display the figure size information\n",
        "    ax.set_title('Lung Nodule Detection')\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91380123",
      "metadata": {
        "id": "91380123"
      },
      "source": [
        "# Conclusion and Next Steps\n",
        "\n",
        "Congratulations! You've trained a custom YOLOv5 model to recognize your custom objects.\n",
        "\n",
        "To improve you model's performance, we recommend first interating on your datasets coverage and quality. See this guide for [model performance improvement](https://github.com/ultralytics/yolov5/wiki/Tips-for-Best-Training-Results).\n",
        "\n",
        "To deploy your model to an application, see this guide on [exporting your model to deployment destinations](https://github.com/ultralytics/yolov5/issues/251).\n",
        "\n",
        "Once your model is in production, you will want to continually iterate and improve on your dataset and model via [active learning](https://blog.roboflow.com/what-is-active-learning/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837d3a3c",
      "metadata": {
        "id": "837d3a3c"
      },
      "outputs": [],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67583f10",
      "metadata": {
        "id": "67583f10"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "source_file_path = '/content/yolov5/yolov5/cancer_Nodules_diagnosed/exp/weights/best.pt'\n",
        "\n",
        "destination_directory = 'weights/'\n",
        "os.makedirs(destination_directory, exist_ok=True)\n",
        "\n",
        "destination_file_path = destination_directory\n",
        "\n",
        "# Copy the file to the destination\n",
        "shutil.copy2(source_file_path, destination_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-1ze3mPLUX4P",
      "metadata": {
        "id": "-1ze3mPLUX4P"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "checkpoint = torch.load('/content/yolov5/weights/best.pt', map_location=torch.device('cpu'), pickle_module=pickle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xASrnyPDYIbk",
      "metadata": {
        "id": "xASrnyPDYIbk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def delete_files_in_dir(directory):\n",
        "    # Iterate over all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            # Check if the path is a file and delete it\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "                print(f\"Deleted {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}: {e}\")\n",
        "\n",
        "# Specify the directory from which you want to delete files\n",
        "directory_to_delete = \"/content/yolov5/weights\"\n",
        "\n",
        "# Call the function to delete files in the specified directory\n",
        "print(directory_to_delete)\n",
        "delete_files_in_dir(directory_to_delete)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83683f38-3c34-4447-bdc3-14c2e1af8f6d",
      "metadata": {
        "id": "83683f38-3c34-4447-bdc3-14c2e1af8f6d"
      },
      "source": [
        "Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_x_dT4lY-tm",
      "metadata": {
        "id": "b_x_dT4lY-tm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4097a44a-aaad-4f38-8591-795be9503b09",
      "metadata": {
        "id": "4097a44a-aaad-4f38-8591-795be9503b09"
      },
      "outputs": [],
      "source": [
        "!pip install SimpleITK\n",
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import SimpleITK as stk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage import measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "geazGUv1W8Sc",
      "metadata": {
        "id": "geazGUv1W8Sc"
      },
      "outputs": [],
      "source": [
        "!pip install nbformat\n",
        "import nbformat as nbf\n",
        "def merge_notebooks(filenames):\n",
        "    merged = nbf.v4.new_notebook()\n",
        "    for fname in filenames:\n",
        "        with ope\n",
        "n(fname) as f:\n",
        "            nb = nbf.read(f, as_version=4)\n",
        "            merged.cells.extend(nb.cells)\n",
        "    return merged\n",
        "\n",
        "notebooks_to_merge =[\"/content/drive/MyDrive/Colab Notebooks/Test_Final_Prediction.ipynb\",\n",
        "                     \"/content/drive/MyDrive/Colab Notebooks/yolov5-on-costume-dataset-lung-cancer-nodules-dete.ipynb\",\n",
        "                     \"/content/drive/MyDrive/Colab Notebooks/custom_ct_scan.ipynb\"]\n",
        "\n",
        "merged_notebook = merge_notebooks(notebooks_to_merge);\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/PulmonaryLungNoduleDetection.ipynb\", \"w\") as f:\n",
        "    nbf.write(merged_notebook, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lmfDyZYRbfzk",
      "metadata": {
        "id": "lmfDyZYRbfzk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3246998e-4cfd-4295-a52b-a55a4c0645a1",
      "metadata": {
        "id": "3246998e-4cfd-4295-a52b-a55a4c0645a1"
      },
      "source": [
        "Path for Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b83e3dde-1fb0-4384-aec4-ce132159ae9a",
      "metadata": {
        "id": "b83e3dde-1fb0-4384-aec4-ce132159ae9a"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/DATA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "950380a4-e10b-4cb2-89f9-1d4f6f23802e",
      "metadata": {
        "id": "950380a4-e10b-4cb2-89f9-1d4f6f23802e"
      },
      "outputs": [],
      "source": [
        "FILE = \"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/imgs/Testimg1.jpg\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b101009a-530f-416e-aa82-9ec98e80391f",
      "metadata": {
        "id": "b101009a-530f-416e-aa82-9ec98e80391f"
      },
      "source": [
        "Function to load mhd files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3068ccc9-1662-496c-b91b-3bc94eeb0d69",
      "metadata": {
        "id": "3068ccc9-1662-496c-b91b-3bc94eeb0d69"
      },
      "outputs": [],
      "source": [
        "def load_mhd(file):\n",
        "    mhdimage = stk.ReadImage(file)\n",
        "    ct_scan = stk.GetArrayFromImage(mhdimage)\n",
        "    origin = np.array(list(mhdimage.GetOrigin()))\n",
        "    space = np.array(list(mhdimage.GetSpacing()))\n",
        "    return ct_scan, origin, space"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dce09483-48d4-4122-bd58-34a0d5cb2e4e",
      "metadata": {
        "id": "dce09483-48d4-4122-bd58-34a0d5cb2e4e"
      },
      "source": [
        "Custom Evaluation metrics for U-Net model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd35975-d7a3-4290-af69-5f8e56f98d7a",
      "metadata": {
        "id": "fbd35975-d7a3-4290-af69-5f8e56f98d7a"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b7a5b16-456c-4318-ad2b-c0ebc252cea3",
      "metadata": {
        "id": "2b7a5b16-456c-4318-ad2b-c0ebc252cea3"
      },
      "source": [
        "Loading U-Net model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3983d1-992f-4f70-b4a8-9b2ea5e7696a",
      "metadata": {
        "id": "3a3983d1-992f-4f70-b4a8-9b2ea5e7696a"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Untitled folder/Lung_Cancer_Detection-main/models/v2/UNet_model.h5\", custom_objects={'dice_coef':dice_coef, 'dice_coef_loss':dice_coef_loss})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f412e825-b8ec-4012-b014-51186558674e",
      "metadata": {
        "id": "f412e825-b8ec-4012-b014-51186558674e"
      },
      "source": [
        "Read Custom CT-Scan (mhd file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff00f6b4-7ded-4654-9df8-a8a7d25f34a1",
      "metadata": {
        "id": "ff00f6b4-7ded-4654-9df8-a8a7d25f34a1"
      },
      "outputs": [],
      "source": [
        "#ct, origin, space = load_mhd(FILE)\n",
        "ct = cv2.imread(FILE)\n",
        "print(ct.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "607f4989-54cf-46ed-bc4b-ba3b1a6d8ead",
      "metadata": {
        "id": "607f4989-54cf-46ed-bc4b-ba3b1a6d8ead"
      },
      "outputs": [],
      "source": [
        "num_z, width,height = ct.shape\n",
        "ct_norm = ct.astype(np.uint8)\n",
        "#ct_norm = cv2.normalize(ct, None, 0, 1, cv2.NORM_MINMAX)\n",
        "ct_norm = cv2.cvtColor(ct, cv2.COLOR_RGB2GRAY)   # Normalizing the CT scan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca68cde2-57c4-4fbf-9d2f-2c410ef49cd4",
      "metadata": {
        "id": "ca68cde2-57c4-4fbf-9d2f-2c410ef49cd4"
      },
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(width,height))\n",
        "##plt.imshow(ct)\n",
        "plt.imshow(ct_norm)\n",
        "#plt.imshow(ct_norm[57], cmap=\"gray\", interpolation=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4432b570-f59e-4629-b709-88b6fb3196d4",
      "metadata": {
        "id": "4432b570-f59e-4629-b709-88b6fb3196d4"
      },
      "outputs": [],
      "source": [
        "ct_norm = cv2.resize(ct_norm, (512,512))\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "ct_norm_improved = clahe.apply(ct_norm.astype(np.uint8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bbad37-89e0-4980-a4a6-fdf4777b9a54",
      "metadata": {
        "id": "f1bbad37-89e0-4980-a4a6-fdf4777b9a54"
      },
      "outputs": [],
      "source": [
        "plt.imshow(ct_norm_improved, cmap = \"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296a1861-5f9d-464c-82e0-d91001e32d8b",
      "metadata": {
        "id": "296a1861-5f9d-464c-82e0-d91001e32d8b"
      },
      "outputs": [],
      "source": [
        "centeral_area = ct_norm_improved[100:400, 100:400]\n",
        "kmeans = KMeans(n_clusters=2).fit(np.reshape(centeral_area, [np.prod(centeral_area.shape), 1]))\n",
        "centroids = sorted(kmeans.cluster_centers_.flatten())\n",
        "threshold = np.mean(centroids)\n",
        "print(threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d1fd706-1afd-478e-a6bf-a4454baa293f",
      "metadata": {
        "id": "6d1fd706-1afd-478e-a6bf-a4454baa293f"
      },
      "outputs": [],
      "source": [
        "    ret, lung_roi = cv2.threshold(ct_norm, threshold, 255, cv2.THRESH_BINARY_INV)\n",
        "    lung_roi = cv2.erode(lung_roi, kernel=np.ones([4,4]))\n",
        "    lung_roi = cv2.dilate(lung_roi, kernel=np.ones([13,13]))\n",
        "    lung_roi = cv2.erode(lung_roi, kernel=np.ones([8,8]))\n",
        "\n",
        "    labels = measure.label(lung_roi)\n",
        "    regions = measure.regionprops(labels)\n",
        "    good_labels = []\n",
        "    for prop in regions:\n",
        "        B = prop.bbox\n",
        "        if B[2]-B[0] < 500 and B[3]-B[1] < 490 and B[0] > 17 and B[2] < 495:\n",
        "            good_labels.append(prop.label)\n",
        "    lung_roi_mask = np.zeros_like(labels)\n",
        "    for N in good_labels:\n",
        "        lung_roi_mask = lung_roi_mask + np.where(labels == N, 1, 0)\n",
        "\n",
        "    contours, hirearchy = cv2.findContours(lung_roi_mask,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    external_contours = np.zeros(lung_roi_mask.shape)\n",
        "    for i in range(len(contours)):\n",
        "        if hirearchy[0][i][3] == -1:  #External Contours\n",
        "            area = cv2.contourArea(contours[i])\n",
        "            if area>518.0:\n",
        "                cv2.drawContours(external_contours,contours,i,(1,1,1),-1)\n",
        "    external_contours = cv2.dilate(external_contours, kernel=np.ones([4,4]))\n",
        "\n",
        "    external_contours = cv2.bitwise_not(external_contours.astype(np.uint8))\n",
        "    external_contours = cv2.erode(external_contours, kernel=np.ones((7,7)))\n",
        "    external_contours = cv2.bitwise_not(external_contours)\n",
        "    external_contours = cv2.dilate(external_contours, kernel=np.ones((12,12)))\n",
        "    external_contours = cv2.erode(external_contours, kernel=np.ones((12,12)))\n",
        "\n",
        "\n",
        "    contours, hirearchy = cv2.findContours(external_contours,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    external_contours2 = np.zeros(external_contours.shape)\n",
        "    lungs_mask =\n",
        "    cv2.resize(external_contours2, ct_norm_improved.shape)\n",
        "    lungs_mask = external_contours2\n",
        "    for i in range(len(contours)):\n",
        "        if hirearchy[0][i][3] == -1:  #External Contours\n",
        "            area = cv2.contourArea(contours[i])\n",
        "            if area>518.0:\n",
        "                cv2.drawContours(external_contours2,contours,i,(1,1,1),-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "etrDczr0FdRJ",
      "metadata": {
        "id": "etrDczr0FdRJ"
      },
      "outputs": [],
      "source": [
        "#!pip install flask gunicorn pyngrok\n",
        "\n",
        "from flask import Flask, request\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define prediction route\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict():\n",
        "    # Your ML model prediction logic here\n",
        "    data = request.json\n",
        "    prediction = model.predict(data)\n",
        "    return {'prediction': prediction}\n",
        "\n",
        "# Run Flask app with Gunicorn\n",
        "def run_flask_with_gunicorn():\n",
        "    !gunicorn -w 4 -b 127.0.0.1:8000 app:app &>/dev/null &\n",
        "\n",
        "# Expose Gunicorn server with Ngrok\n",
        "def expose_with_ngrok():\n",
        "    public_url = ngrok.connect(port='8000')\n",
        "    print('Ngrok URL:', public_url)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_flask_with_gunicorn()\n",
        "    expose_with_ngrok()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d88eb0-e7fa-4f0d-873b-2d85c22282e0",
      "metadata": {
        "id": "b9d88eb0-e7fa-4f0d-873b-2d85c22282e0"
      },
      "outputs": [],
      "source": [
        "plt.imshow(lungs_mask, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31e9e3e2-7753-4cc9-8277-48a1edd220a5",
      "metadata": {
        "id": "31e9e3e2-7753-4cc9-8277-48a1edd220a5"
      },
      "outputs": [],
      "source": [
        "#extracted_lungs = (cv2.bitwise_and(ct_norm_improved, ct_norm_improved, mask=mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bea73226-53fb-43b3-ac7f-323e321028a4",
      "metadata": {
        "id": "bea73226-53fb-43b3-ac7f-323e321028a4"
      },
      "outputs": [],
      "source": [
        "plt.imshow(extracted_lungs, cmap=\"bone\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfefc4f2-e7f4-49c2-ab7b-7bc00f0d4c0b",
      "metadata": {
        "id": "bfefc4f2-e7f4-49c2-ab7b-7bc00f0d4c0b"
      },
      "outputs": [],
      "source": [
        "X = np.array(extracted_lungs)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c86a20-89ba-4079-be71-abe272d4a79a",
      "metadata": {
        "id": "53c86a20-89ba-4079-be71-abe272d4a79a"
      },
      "outputs": [],
      "source": [
        "X = (X-127.0)/127.0\n",
        "X = X.astype(np.float32)\n",
        "X.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937b6522-d405-4084-8403-3d4535c89c09",
      "metadata": {
        "id": "937b6522-d405-4084-8403-3d4535c89c09"
      },
      "outputs": [],
      "source": [
        "print(\"Min:\",X.min(),\"\\nMax:\",X.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23c52e49-1415-4f5e-a210-fbe893ee6348",
      "metadata": {
        "id": "23c52e49-1415-4f5e-a210-fbe893ee6348"
      },
      "outputs": [],
      "source": [
        "X = np.reshape(X, (len(X), 512, 512, 1))\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "653d5755-5b32-4e5a-a7a3-19d5201a06eb",
      "metadata": {
        "id": "653d5755-5b32-4e5a-a7a3-19d5201a06eb"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X)\n",
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea279ed-31db-4d60-ba54-99a8c98be9f8",
      "metadata": {
        "id": "eea279ed-31db-4d60-ba54-99a8c98be9f8"
      },
      "outputs": [],
      "source": [
        "print(\"Dtype:\",predictions.dtype,\"\\nMin:\",predictions.min(),\"\\nMax:\",predictions.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6898a5c4-e240-44b2-a7ff-5ae38850943c",
      "metadata": {
        "id": "6898a5c4-e240-44b2-a7ff-5ae38850943c"
      },
      "outputs": [],
      "source": [
        "predictions[predictions>=0.5] = 255\n",
        "predictions[predictions<0.5] = 0\n",
        "predictions = predictions.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "845c977e-fcce-4eca-ad87-58a4f7c14e27",
      "metadata": {
        "id": "845c977e-fcce-4eca-ad87-58a4f7c14e27"
      },
      "outputs": [],
      "source": [
        "pred = list(predictions)\n",
        "pred = [np.squeeze(i) for i in pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16643845-0727-4368-8b7d-ad76f9a65ccb",
      "metadata": {
        "id": "16643845-0727-4368-8b7d-ad76f9a65ccb"
      },
      "outputs": [],
      "source": [
        "plt.imshow(pred[61], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb21c48-8bf2-4999-b629-c35bee1c0351",
      "metadata": {
        "id": "1eb21c48-8bf2-4999-b629-c35bee1c0351"
      },
      "outputs": [],
      "source": [
        "def display(imgs,mask):\n",
        "    j = 1\n",
        "    for im,mk in zip(imgs,mask):\n",
        "        plt.figure(figsize=(20,300))\n",
        "        plt.subplot(50,3,j)\n",
        "        plt.imshow(np.squeeze(im), cmap=\"gray\")\n",
        "        plt.subplot(50,3,j+1)\n",
        "        plt.imshow(np.squeeze(mk), cmap=\"gray\")\n",
        "        plt.subplot(50,3,j+2)\n",
        "        plt.imshow(cv2.addWeighted(np.squeeze(im), .5, np.squeeze(mk), .5, 0), cmap=\"gray\")\n",
        "        j += 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4efdbc-fb85-49c5-80ef-04aed5fd0aa5",
      "metadata": {
        "id": "4c4efdbc-fb85-49c5-80ef-04aed5fd0aa5"
      },
      "outputs": [],
      "source": [
        "def display2(imgs, titles=None, cmap=\"bone\"):\n",
        "    n = len(list(imgs))\n",
        "    r = n//3 if n%3==0 else (n//3)+1\n",
        "    plt.figure(figsize=(25,int(8*r)))\n",
        "    for i,img in enumerate(imgs):\n",
        "        plt.subplot(r,3,i+1)\n",
        "        if titles is not None:\n",
        "            plt.title(titles[i])\n",
        "        plt.imshow(img, cmap=cmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ce3de6-b13c-4f46-aa10-aa41a157159a",
      "metadata": {
        "id": "12ce3de6-b13c-4f46-aa10-aa41a157159a"
      },
      "outputs": [],
      "source": [
        "display(extracted_lungs[65:70],pred[65:70])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792e1cdb-6b63-4456-a911-8b5cd5e74f1e",
      "metadata": {
        "id": "792e1cdb-6b63-4456-a911-8b5cd5e74f1e"
      },
      "outputs": [],
      "source": [
        "bboxes = []\n",
        "centroids = []\n",
        "diams = []\n",
        "for mask in pred:\n",
        "    mask = cv2.dilate(mask, kernel=np.ones((5,5)))\n",
        "    labels = measure.label(mask)\n",
        "    regions = measure.regionprops(labels)\n",
        "    bb = []\n",
        "    cc = []\n",
        "    dd = []\n",
        "    for prop in regions:\n",
        "        B = prop.bbox\n",
        "        C = prop.centroid\n",
        "        D = prop.equivalent_diameter_area\n",
        "        bb.append((( max(0, B[1]-8), max(0, B[0]-8) ),( min(B[3]+8, 512), min(B[2]+8, 512) )))    # ((x1,y1),(x2,y2))\n",
        "        cc.append(C)    # (y,x)\n",
        "        dd.append(D)\n",
        "    bboxes.append(bb)\n",
        "    centroids.append(cc)\n",
        "    diams.append(dd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7922e2d7-e869-4c7c-bbd3-d82c633ee328",
      "metadata": {
        "id": "7922e2d7-e869-4c7c-bbd3-d82c633ee328"
      },
      "outputs": [],
      "source": [
        "bboxes[65:71]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1963338-04c8-49fe-be8e-01775952162a",
      "metadata": {
        "id": "b1963338-04c8-49fe-be8e-01775952162a"
      },
      "outputs": [],
      "source": [
        "centroids[65:71]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0df167-a767-4022-a3b2-fc906a759a3c",
      "metadata": {
        "id": "2c0df167-a767-4022-a3b2-fc906a759a3c"
      },
      "outputs": [],
      "source": [
        "diams[65:71]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396407fc-6e67-40fb-bbf2-1bd04f941e60",
      "metadata": {
        "id": "396407fc-6e67-40fb-bbf2-1bd04f941e60"
      },
      "outputs": [],
      "source": [
        "bs = []\n",
        "mimgs = copy.deepcopy(extracted_lungs)\n",
        "for i,(img,boxes) in enumerate(zip(mimgs,bboxes)):\n",
        "    for rect in boxes:\n",
        "        img = cv2.rectangle(img, rect[0], rect[1], (255), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7011385a-56c7-40ec-b4f6-345ad8dd17b5",
      "metadata": {
        "id": "7011385a-56c7-40ec-b4f6-345ad8dd17b5"
      },
      "outputs": [],
      "source": [
        "display2(mimgs[40:55])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10bc701c-016d-40a4-a10e-ff2b66176ff7",
      "metadata": {
        "id": "10bc701c-016d-40a4-a10e-ff2b66176ff7"
      },
      "outputs": [],
      "source": [
        "idx = 66\n",
        "v = copy.deepcopy(extracted_lungs)\n",
        "plt.figure(figsize=(10,10))\n",
        "i = cv2.rectangle(v[idx], bboxes[idx][0][0], bboxes[idx][0][1], (255), 2)\n",
        "i = cv2.circle(i, (int(centroids[idx][0][1]), int(centroids[idx][0][0])), 2, (255), -1)\n",
        "plt.imshow(i, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5ed0b3-b8db-4c10-bed1-18706e8e2467",
      "metadata": {
        "id": "7c5ed0b3-b8db-4c10-bed1-18706e8e2467"
      },
      "outputs": [],
      "source": [
        "diams[66][0]*space[0]   # diameter in mm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225bd0ed-44dc-4d76-b614-53f7a3501a1b",
      "metadata": {
        "id": "225bd0ed-44dc-4d76-b614-53f7a3501a1b"
      },
      "outputs": [],
      "source": [
        "fpr_model = tf.keras.models.load_model(\"models/FPR_classifier_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "674c5c82-a830-4ab8-9bad-ba97e73e853a",
      "metadata": {
        "id": "674c5c82-a830-4ab8-9bad-ba97e73e853a"
      },
      "outputs": [],
      "source": [
        "originals = copy.deepcopy(ct_norm_improved)\n",
        "final_boxes = []\n",
        "for i,(img,bbox) in enumerate(zip(originals, bboxes)):\n",
        "    img_boxes = []\n",
        "    for box in bbox:\n",
        "        x1 = box[0][0]\n",
        "        y1 = box[0][1]\n",
        "        x2 = box[1][0]\n",
        "        y2 = box[1][1]\n",
        "        if abs(x1-x2) <=50 or abs(y1-y2)<=50:\n",
        "            x = (x1+x2)//2\n",
        "            y = (y1+y2)//2\n",
        "            x1 = max(x-25, 0)\n",
        "            x2 = min(x+25, 512)\n",
        "            y1 = max(y-25, 0)\n",
        "            y2 = min(y+25, 512)\n",
        "            imgbox = img[y1:y2,x1:x2]\n",
        "            img_boxes.append(imgbox)\n",
        "        else:\n",
        "            imgbox = img[y1:y2,x1:x2]\n",
        "            img_boxes.append(imgbox)\n",
        "    final_boxes.append(img_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79a88de-f4a0-4ca1-b64e-e4a8a378f8ab",
      "metadata": {
        "id": "f79a88de-f4a0-4ca1-b64e-e4a8a378f8ab"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i,img in enumerate(final_boxes[66]):\n",
        "    plt.subplot(1,6,i+1)\n",
        "    plt.imshow(img, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a315562-6bb0-4913-98fd-62afab2e0294",
      "metadata": {
        "id": "4a315562-6bb0-4913-98fd-62afab2e0294"
      },
      "outputs": [],
      "source": [
        "fpr_preds = []\n",
        "for i in final_boxes:\n",
        "    each_p = []\n",
        "    for img in i:\n",
        "        if img.shape != (50,50):\n",
        "            img = np.resize(img, (50,50))\n",
        "        img = img/255.\n",
        "        img = np.reshape(img, (1,50,50,1))\n",
        "        pred = fpr_model.predict(img)\n",
        "        pred = int(pred>=0.5)\n",
        "        each_p.append(pred)\n",
        "    fpr_preds.append(each_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73067a93-2d6f-49e7-ac10-30c02479bcaa",
      "metadata": {
        "id": "73067a93-2d6f-49e7-ac10-30c02479bcaa"
      },
      "outputs": [],
      "source": [
        "bboxes[66]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3184dc70-ed34-4948-8bfa-4d0279e5c0b4",
      "metadata": {
        "id": "3184dc70-ed34-4948-8bfa-4d0279e5c0b4"
      },
      "outputs": [],
      "source": [
        "for i in range(len(diams)):\n",
        "    if len(diams[i]):\n",
        "        for j in range(len(diams[i])):\n",
        "            diams[i][j] = diams[i][j]*space[0]       # diameters in mm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69aa959d-d239-4ac2-acdd-3d354300726c",
      "metadata": {
        "id": "69aa959d-d239-4ac2-acdd-3d354300726c"
      },
      "outputs": [],
      "source": [
        "final_img_bbox = []\n",
        "cancer = []\n",
        "df = pd.DataFrame(columns = ['Layer', 'Position (x,y)', 'Diameter (mm)', 'BBox [(x1,y1),(x2,y2)]'])\n",
        "e_lungs = copy.deepcopy(ct_norm_improved)\n",
        "for i,(img,bbox,preds,cents,dms) in enumerate(zip(e_lungs, bboxes, fpr_preds, centroids, diams)):\n",
        "    token = False\n",
        "    for box,pred,cent,dm in zip(bbox,preds,cents,dms):\n",
        "        if pred:\n",
        "            x1 = box[0][0]\n",
        "            y1 = box[0][1]\n",
        "            x2 = box[1][0]\n",
        "            y2 = box[1][1]\n",
        "            img = cv2.rectangle(img, (x1,y1), (x2,y2), (255), 2)\n",
        "            dct = pd.DataFrame({'Layer':i, 'Position (x,y)':[f\"{cent[::-1]}\"], 'Diameter (mm)':dm, 'BBox [(x1,y1),(x2,y2)]':[f\"{list(box)}\"]})\n",
        "            df = pd.concat([df,dct], ignore_index = True)\n",
        "            token = True\n",
        "    final_img_bbox.append(img)\n",
        "    cancer.append(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db01eac6-5382-449e-9dff-455bbcee53da",
      "metadata": {
        "id": "db01eac6-5382-449e-9dff-455bbcee53da"
      },
      "outputs": [],
      "source": [
        "display2(final_img_bbox[60:72])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d2b0d3-1f5e-4a75-b046-3209f5d0c7a2",
      "metadata": {
        "id": "a9d2b0d3-1f5e-4a75-b046-3209f5d0c7a2"
      },
      "outputs": [],
      "source": [
        "cancer[60:72]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbeced39-8dc1-46cb-b056-e6a5f1cb4827",
      "metadata": {
        "id": "fbeced39-8dc1-46cb-b056-e6a5f1cb4827"
      },
      "outputs": [],
      "source": [
        "df = df.reset_index(drop=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a363febc-c85c-40b9-b227-d8e7f943e2d6",
      "metadata": {
        "id": "a363febc-c85c-40b9-b227-d8e7f943e2d6"
      },
      "outputs": [],
      "source": [
        "folder = FILE.replace(\".mhd\", \"\")\n",
        "os.mkdir(f\"results/{folder}\")\n",
        "df.to_csv(f\"results/{folder}/detections.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86194505-7f6e-45e9-9763-ea9368242e1e",
      "metadata": {
        "id": "86194505-7f6e-45e9-9763-ea9368242e1e"
      },
      "outputs": [],
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "vid = cv2.VideoWriter(f\"results/{folder}/detections.mp4\", fourcc, 5.0, (512,512), False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a6aed6-60fa-4b21-a8f6-0a9419bed3e6",
      "metadata": {
        "id": "74a6aed6-60fa-4b21-a8f6-0a9419bed3e6"
      },
      "outputs": [],
      "source": [
        "for i in range(len(final_img_bbox)):\n",
        "    img = final_img_bbox[i].copy()\n",
        "    img = cv2.putText(img, f\"Layer: {i}\", (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255), 2)\n",
        "    vid.write(img)\n",
        "vid.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9288d2b6-50c2-4fdc-80c3-200b94365756",
      "metadata": {
        "id": "9288d2b6-50c2-4fdc-80c3-200b94365756"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}